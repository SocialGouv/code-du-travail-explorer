#

Install nlp:
  extends: .prepare_stage
  image: python:3.7-alpine3.11
  interruptible: true
  variables:
    CONTEXT: code-du-travail-nlp
    PIP_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/pip"
    PYTHONUSERBASE: "${CI_PROJECT_DIR}/python_user_packages"
  script:
    - source .gitlab-ci/f1_scripts.sh
    #
    - >-
      if [[ -z ${NO_CACHE} ]]; then
        checking_cache "${CI_COMMIT_REF_SLUG}/${CONTEXT}-python_user_packages.tar.gz" || \
        (echo "" && checking_cache ${CI_DEFAULT_BRANCH}/${CONTEXT}-python_user_packages.tar.gz) || \
        true
      fi
    #
    - sha1sum packages/${CONTEXT}/requirements.txt > PACKAGE_SHA
    - cat PACKAGE_SHA
    - >-
      if [[ -d ${CI_PROJECT_DIR}/python_user_packages ]] && cmp -s PACKAGE_SHA SHA ; then
        echo "No changes detected."
        exit ${CI_JOB_SKIP_EXIT_CODE:-0}
      else
        echo "Changes detected."
        rm -rf ${CI_PROJECT_DIR}/python_user_packages
        mv PACKAGE_SHA SHA
      fi
    #
    - >-
      if [[ -z ${NO_CACHE} ]]; then
        checking_cache "${CI_COMMIT_REF_SLUG}/${CONTEXT}-pip.tar.gz" || \
        (echo "" && checking_cache ${CI_DEFAULT_BRANCH}/${CONTEXT}-pip.tar.gz) || \
        true
      fi
    #
    - cd packages/${CONTEXT}
    - pip install --user -r requirements.txt
    #
    - creating_cache ${CONTEXT}-pip.tar.gz .cache/pip || true
    - creating_cache ${CONTEXT}-node_modules.tar.gz SHA ${CI_PROJECT_DIR}/python_user_packages || true

  artifacts:
    expire_in: 30 mins
    paths:
      - ${CI_PROJECT_DIR}/python_user_packages

#

Build @cdt/nlp:
  extends: .quality_stage
  stage: "Build"
  dependencies:
    - Build @cdt/data
    - Install nlp
  needs:
    - Build @cdt/data
    - Install data
    - Install nlp
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/packages/code-du-travail-nlp"
    PYTHONUSERBASE: "${CI_PROJECT_DIR}/python_user_packages"
  image: python:3.7-slim-buster
  script:
    # - find packages/code-du-travail-api/src -type f \( -exec sha1sum {} \; \) | sha1sum
    # - sha1sum yarn.lock packages/${CONTEXT}/package.json > PACKAGE_SHA
    # - cat PACKAGE_SHA
    # - >-
    #   if [[ -d node_modules ]] && cmp -s PACKAGE_SHA SHA ; then
    # Copy the `@cdt/data` artefact to the nlp data directory
    - cp ./packages/code-du-travail-data/dist/dump.data.json
        ./packages/code-du-travail-nlp/data/dump.json
    #
    - cd packages/code-du-travail-nlp
    - export PATH=$PATH:$PYTHONUSERBASE/bin
    - python ./scripts/dump.py
  artifacts:
    expire_in: 30 mins
    paths:
      - packages/code-du-travail-nlp/data/dump.tf.json

#

Register nlp image:
  extends:
    - .base_register_stage
    - .register_stage
  variables:
    CONTEXT: packages/code-du-travail-nlp
    DOCKER_BUILD_ARGS: >-
      --build-arg SUGGEST_DATA_URL=$SUGGEST_DATA_URL
    IMAGE_NAME: $CI_REGISTRY_IMAGE/nlp

#

.deploy_nlp_stage:
  extends:
    - .base_deploy_nodejs_chart_stage
    - .deploy_stage
    - .dev_stage
  variables:
    IMAGE_TAG: master
    PORT: ${NLP_PORT}
    CONTEXT: nlp
    VALUES_FILE: ./.k8s/nlp.values.yml
  before_script:
    - source ./.gitlab-ci/env.sh
    - HOST=${NLP_HOST}

#

Deploy @cdtn/nlp (dev):
  extends:
    - .deploy_nlp_stage
    - .dev_stage

# Deploy @cdtn/nlp (prod):
#   extends:
#     - .deploy_nlp_stage
#     - .dev_stage
